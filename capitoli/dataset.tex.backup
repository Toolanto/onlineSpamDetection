\chapter{Dataset e strumenti utilizzati}
\lstset{basicstyle=\small\ttfamily,keywordstyle=\color{black}\bfseries,commentstyle=\color{darkgray},stringstyle=\color{black},showstringspaces=true} 
Questo capitolo illustra il dataset utilizzato per l'implementazione e l'esecuzione dei test,  che verrano discussi nel capitolo successivo, e gli strumenti (tra cui framework e librerie) utilizzati per rendere più efficienti i vari test.
\section{Descrizione del dataset}
Il dataset utilizzato per gli espirementi è WEBSPAM-UK2007 \cite{webspam-uk2007} ottenuto da un crawl del dominio ``.uk'' nel maggio del 2007 tramite il supporto del ``Laboratorio di Algoritmica per il Web'' dell'Università degli Studi di Milano; è composto da un insieme di 105.896.555 pagine che fanno parte di 114.529 host. Gli host del dataset  sono etichettati,  grazie al supporto  di alcuni volontari,  in due classi: nodi spam e nodi non spam . Il dataset è composto da tre parti:
\begin{itemize}
 \item La prima parte contiene le etichette associate agli host (divise in due gruppi). Il primo gruppo è costituito da 2/3 dell'insieme degli host valutati, ed è pensato stato pensato per essere utilizzato come dataset di traning. Questo primo gruppo è costituito da 3776 nodi etichettati come non spam, 222 nodi etichettati spam ed infine 277 nodi etichettati ``undecided'' ovvero nodi di cui la natura (spam o non spam) è in dubbio. Il secondo gruppo di etichette costituito dal rimanente 1/3 dell'insieme degli host valutati, è stato pensato per essere utilizzato come dataset di testing. Il secondo gruppo è costituito da 1933 nodi etichettati non spam, 122 nodi etichettati spam e 149 etichettati ``undecided''. \\ Tutti gli host sono identificati attraverso un \textit{id}, che va da 0 a 114.528, a cui è associato l'URL corrispondente.
 L'assegnazione di un'etichetta ad un host avviene in due fasi. Nella prima fase l'utente valuta ogni host sulla base del contenuto della collezione e la lista degli host collegati all'host valutato. Nella seconda fase all'utente valutatore vengono fornite l'etichette  assegnate dagli altri utenti ad ogni host valutato e gli viene chiesto di riesaminare le sue valutazioni qualora vi fosse un disaccordo con altri. Le etichette ottenute tramite tale processo vengono sintetizzate in un file. Il file esplica per ogni host valutato, il suo \textit{id}  e l'etichetta associata tra ``nonspam'',``spam'' e ``undecided''; oltre all'etichetta sono associate le singole valutazioni effettuate dagli utenti e la media risultante delle valutazioni effettuate per un dato host, calcolata considerando l'etichetta spam uguale a 1, l'etichetta non spam  uguale a 0 e l'etichetta di ``undecided'' uguale 0.5.\\
Di seguito è rappresentato un esempio con 5 host: 
 \begin{lstlisting}[frame=trbl,postbreak=\space, breakindent=5pt, breaklines]
ID ETICHETTA MEDIA VALUTAZIONI
5 nonspam 0.00000 j1:N,j2:N
100 nonspam 0.33333 j14:N,j17:S,j7:N
120 spam 1.00000 j18:U,j4:S
170 undecided - j13:U,j20:U
210 undecided 0.50000 j15:N,j16:S,j22:U
\end{lstlisting}
Dove \(N\) indica non spam, \(S\) indica spam e \(U\) indica che la natura del nodo non è definita. Prendendo, ad esempio, in cosiderazione l'host con \textit{id} uguale a 5 si può notare che tale nodo è stato giudicato non spam e che la media delle due votazioni è uguale a 0, visto che entrambi gli utenti hanno giudicato il nodo non spam.\\ 
Le informazioni appena descritte risultano oltre modo dettagliate per i test che devono essere esguiti in questo lavoro di tesi e dal momento che si ha solo bisogno di sapere quali nodi siano spam e quali non spam sono stati utilizzati solo i dati relativi alle etichette associate ai nodi del primo gruppo (il gruppo di testing).

 
 \item La seconda parte contiene il grafo definito con due differenti livelli di granularità. Quindi ci sono due grafi uno definito a livello di host mentre un secondo grafo è definito a livello di pagina. Il grafo a livello di host (che poi sarà quello utilizzato per eseguire i test) è formato da 114.528 nodi (rappresentanti gli host) mentre il secondo è formato  105.896.555 di nodi (rappresentanti le pagine web)  connessi da circa 3.7 miliardi di archi (ovvero i link tra le pagine). Il grafo degli host gestisce i link mutipli tra gli URL aggregando i vari link tra le pagine di differenti host in un singolo link a cui è associato un peso.\\
 Il file che descrive il grafo a livello di host ha una particolare sintassi: la prima riga indica il numero di host nel grafo mentre le successive righe contengono gli \textit{outlink} degli host, ad esempio alla riga due verranno indicati gli \textit{outlink} del nodo 0 alla riga tre gli \textit{outlink} del nodo 1 e cosi via. Dato che i link sono pesati la sintassi completa per ogni riga che rappressenta un nodo è:
 $$
 dest_1:nlinks_1,dest_2:nlinks_2,...,dest_k:nlinks_k
 $$
 dove \(dest\) è il nodo di arrivo del link ed è rappresentato dall'\textit{id} del nodo di destinazione mentre \(nlinks\) è il numero di link tra le pagine dei due host.
 Ad esempio di seguito è illustrato una porzione di un grafo degli host:
\begin{lstlisting}[frame=trbl,postbreak=\space, breakindent=5pt, breaklines]
114529
1005:1 8306:1 9596:1 
8107:3320 22950:4 108053:1
24003:1
24003:1
...
\end{lstlisting}
Nella prima riga dell'esempio viene specificato che il grafo è composto da 114529 nodi. Nella seconda riga si nota che il nodo 0 ha 3 outlink, uno verso il nodo 1005, un altro link verso il nodo 9596 ed infine un link verso il nodo 8306. La terza riga indica che il nodo 1 ha 3 outlink: un link verso il nodo 8107 con un peso 3320 (quindi le pagine del nodo 1 hanno 3320 link verso le pagine del nodo 8107), un link verso il nodo 22950 con peso 4 ed infine un link verso il nodo 108053. Il file quindi sarà lungo 114530 righe.\\
%nel nostro caso non sono state usate le informazioni sui pesi degli archi si è scelto di eliminare tale informazione
Quindi utilizzando queste informazioni si può convertire il file che descrive il grafo in  in modo da poter essere successivamente manipolato tramite il framework WebGraph \cite{Boldi03thewebgraph}.
%si può inserire come fare la conversione
\item La terza parte contiene il contenuto delle pagine HTML fornito in formato WARC. ``Il formato WARC specifica un metodo per combinare molte risorse in un unico file con le relative informazioni'' (\url{http://www.digitalpreservation.gov/formats/fdd/fdd000236.shtml} il 5/5/2014).
\end{itemize}

Quindi per lo sviluppo dei test sono state utilizzate due informazioni utili derivate dal dataset: le etichette che identificano i nodi del grafo spam da quelli che sono non spam e la struttura del grafo che verrà manipolata tramite l'utilizzo del framework WebGraph \cite{Boldi03thewebgraph}. WebGraph è un framework per la compressione di enormi grafi e permette, quindi, di eseguire operazioni sul grafo in maniera molto semplice e veloce. 

\section{La Tau di Kendall}
Alcuni test che sono stati implementati hanno come obbiettivo il calcolo della distanza tra due vettori e quindi per tale motivo è stata utilizzata la Tau di Kendall \cite{KendallTau}. Più precisamente la Tau di Kendall valuta il grado di similarità tra due vettori ovvero dati due vettori \(r_i\) e \(s_i\) con \(i=0,1,...,n-1\) e \(i<j\), si dice che una coppia \((i,j)\) è:
\begin{itemize}
 \item \textit{concordante} se \(r_i-r_j\) e \(s_i-s_j\) sono entrambe diverse da 0 e hanno lo stesso segno;
 \item \textit{discordante} se \(r_i-r_j\) e \(s_i-s_j\) sono entrambe diverse da 0 e hanno segno opposto;
 \item \textit{r-tie} se \(r_i-r_j=0\);
 \item \textit{s-tie} se \(s_i-s_j=0\);
 \item \textit{joint tie} se \(r_i-r_j=0\) e \(s_i-s_j=0\).
\end{itemize}
Allora viene definito  \(C\) come il numero delle coppie concordanti, \(D\) il numero delle coppie discordanti, \(T_r\) il numero delle coppie r-tie, \(T_s\) il numero delle coppie s-tie ,\(J\) il numero delle coppie joint tie e \(N=n(n-1)/2\). Quindi \(C+D+T_r+T_s-J = N\). La Tau di Kendall può essere calcolata come:
\begin{equation}
 \tau = \frac{(C-D)}{[(N-T_r)(N-T_S)]^{1/2}}
\end{equation}
Per eseguire i test è stato scelto di usare la libreria  ``it.unimi.dsi.law'' \cite{libreriaLaw} fornita dal LAW (Laboratori di Algoritmica per il Web) dell'Università degli studi di Milano. Questa libreria contiene dei metodi che consentono di calcolare efficientemente la Tau di Kendall.

\section{Il framework Webgraph}
Per la gestione del grafo è stato usato il framework WebGraph \cite{Boldi03thewebgraph}. Questo framework permette di comprimere i grafi e di eseguire delle operazioni su di essi in maniera molto efficiente. Nell'implementazione dei test viene utilizzata solo una piccola parte delle risorse che mette a disposizine WebGraph. Infatti esso incorpora:
\begin{itemize}
 \item un insieme di codici di compressione per la memorizzazione dei grafi;
 \item algoritmi che permettono di accedere al grafo compresso senza ogni volta doverlo decomprimere;
 \item algoritmi di analisi dei grafi;
 \item insiemi di dati che si possono analizzare.
\end{itemize}
Dal momento che i nostri test esaminano delle proprietà di alcuni algoritmi sui grafi, questo framework rende le operazioni molto efficienti.

