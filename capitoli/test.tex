\chapter{Test dei metodi di spam detection}
\lstset{basicstyle=\small\ttfamily,keywordstyle=\color{black}\bfseries,commentstyle=\color{darkgray},stringstyle=\color{black},showstringspaces=true} 
Nei capitoli precendenti sono stati illustrati vari metodi che di spam detection classificati basandosi sui segnali in ingresso che essi hanno bisogno per poter identificare le pagine web; quindi si hanno tre classi: metodi basati sul contenuto, metodi basati sul grafo e metodi che utilizzano segnali diversi dai primi due. Tra questi metodi ne sono stati presi in esame due: \textit{Trustrank} e \textit{Anti-trust rank}. 

Si è scelto, quindi, di valutare l'efficacia degli algoritmi di \textit{Trustrank} e \textit{Anti-trust rank} se essi operassero in modo online. Più precisamente i vari test consistono nel verificare quanto questi due algoritmi di tipo offline riescano ad approssimare il loro comportamento se li facessimo operare in modo online ovvero durante la fase di crawling.

\section{Descrizione del dataset}
Il dataset utilizzato per gli espirementi è WEBSPAM-UK2007 \cite{webspam-uk2007} ottenuto da un crawl del dominio ``.uk'' nel maggio del 2007, grazie al supporto del ``Laboratorio di Algoritmica per il Web'' dell'Università degli Studi di Milano; è composto da un insieme di 105.896.555 pagine che fanno parte di 114.529 host. I dati di questo dataset, rappresentati degli host, sono stati etichiettati in spam o non spam per mezzo di alcuni volontari. Il dataset è composto da tre parti:
\begin{itemize}
 \item Le etichette associate agli host divise in due gruppi. Il primo gruppo è costituito da 2/3 dell'insieme degli host valutati, è fornito per essere come dataset di traning ed è costituito da 3776 nodi etichettati come non spam, 222 nodi etichettati spam ed infine 277 nodi etichettati ``undecided'' ovvero nodi di cui la natura (spam o non spam) è in dubbio. Il secondo gruppo di etichette contiene il rimanente 1/3 dell'insieme degli host valutati, è fornito per essere utilizzato come dataset di testing ed è costituito da 1933 nodi etichettati non spam, 122 nodi etichettati spam e 149 etichettati ``undecided''.\\
 Le etichette sono associate in due fasi. Nella prima fase l'esaminatore ha a diposizione solo il contenuto della collezione e la lista degli host collegati per ogni host valutato. Nella seconda fase, invece, ha accesso all'etichette, per un nodo, assegnate da altri utenti e gli viene richiesto di rivalutare le sue valutazioni se è in disaccordo con altri. Quindi viene realizzato un file che contiene tali informazioni.\\ 
 Gli host sono identificati attraverso un \textit{id} che va da 0 a 114.528 a cui è associato l'URL corrispondente. Quindi un file specifica per ogni \textit{id} un'etichetta tra ``nonspam'',``spam'' e ``undecided'', oltre all'etichetta vengono associate le singole valutazioni effettuate dagli utenti e la media risultante delle valutazioni effettuate per quell'host tenendo conto che l'etichetta spam è uguale a 1, l'etichetta non spam è uguale a 0 e l'etichetta di ``undecided'' ha valore 0.5. Un esempio è rappresentato di seguito: 
 \begin{lstlisting}[frame=trbl,postbreak=\space, breakindent=5pt, breaklines]
ID ETICHETTA MEDIA VALUTAZIONI
5 nonspam 0.00000 j1:N,j2:N
100 nonspam 0.33333 j14:N,j17:S,j7:N
120 spam 1.00000 j18:U,j4:S
170 undecided - j13:U,j20:U
210 undecided 0.50000 j15:N,j16:S,j22:U
\end{lstlisting}
Nell'esempio vengono rappresentati 5 host; prendendo in cosiderazione l'host con \textit{id} uguale a 5 si nota subito che è stato giudicato come nodo non spam e che la media delle due votazioni è uguale a 0 visto che entrambi gli utenti hanno giudicato il nodo non spam (es. j1:N; N indica non spam, S indica spam e U indica che la natura del nodo non è definita).
 
 \item URL e i collegamenti fra gli URL descritti in formato webgraph;
 
 \item il contenuto delle pagine HTML.
\end{itemize}

